{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:6571\n",
      "top few tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/14/2012</td>\n",
       "      <td>PM 11:11:49</td>\n",
       "      <td>Id rather &lt;a&gt;vote&lt;/a&gt; for &lt;e&gt;Romney&lt;/e&gt; than ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/15/2012</td>\n",
       "      <td>PM 3:19:15</td>\n",
       "      <td>Gallup shows&lt;e&gt; Romney&lt;/e&gt;&lt;a&gt; pulling ahead &lt;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/14/2012</td>\n",
       "      <td>AM 7:29:37</td>\n",
       "      <td>By record-high margin, &lt;a&gt;debate&lt;/a&gt; watchers...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>0.420463</td>\n",
       "      <td>&lt;e&gt;Romney&lt;/e&gt; will make 'great' &lt;a&gt;president&lt;/...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/15/2012</td>\n",
       "      <td>PM 2:34:27</td>\n",
       "      <td>@GOTV2012 \"Mitt &lt;e&gt;Romney&lt;/e&gt; might just &lt;a&gt;s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date          time  \\\n",
       "0           10/14/2012   PM 11:11:49   \n",
       "1           10/15/2012    PM 3:19:15   \n",
       "2           10/14/2012    AM 7:29:37   \n",
       "3  2012-10-16 00:00:00      0.420463   \n",
       "4           10/15/2012    PM 2:34:27   \n",
       "\n",
       "                                     Anootated tweet  Class  \n",
       "0   Id rather <a>vote</a> for <e>Romney</e> than ...      1  \n",
       "1   Gallup shows<e> Romney</e><a> pulling ahead <...      1  \n",
       "2   By record-high margin, <a>debate</a> watchers...      1  \n",
       "3  <e>Romney</e> will make 'great' <a>president</...      1  \n",
       "4   @GOTV2012 \"Mitt <e>Romney</e> might just <a>s...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_excel('training-Obama-Romney-tweets.xlsx', sheetname = 'Romney')\n",
    "inputFrame = df2\n",
    "inputFrame.dropna(inplace = True)\n",
    "print('Total number of tweets:'+str(len(inputFrame)))\n",
    "print('top few tweets:')\n",
    "inputFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "2892\n",
      "1679\n"
     ]
    }
   ],
   "source": [
    "inputFrame_test = inputFrame.copy()\n",
    "inputFrame_test['Class'] = inputFrame_test['Class'].astype(str) \n",
    "inputFrame1 = inputFrame_test[inputFrame_test.Class == '1']\n",
    "inputFrame2 = inputFrame_test[inputFrame_test.Class == '-1']\n",
    "inputFrame3 = inputFrame_test[inputFrame_test.Class == '0']\n",
    "inputFrame = pd.concat([inputFrame1, inputFrame2, inputFrame3])\n",
    "tweetProcessFrame = inputFrame\n",
    "print(len(inputFrame1))\n",
    "print(len(inputFrame2))\n",
    "print(len(inputFrame3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing (cleaning the tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleaning tweets\n",
    "pwords,words=None, None\n",
    "\n",
    "with open(\"positive-words.txt\") as f:\n",
    "    pwords = [el.strip() for el in f.readlines()]\n",
    "with open(\"negative-words.txt\") as f:\n",
    "    nwords = [el.strip() for el in f.readlines()]\n",
    "emoticons_dict = {}\n",
    "def populateEmoticonsDict():\n",
    "    fileHandler = open('EmoticonsWithPolarity.txt', 'r')\n",
    "    for line in fileHandler:\n",
    "        emoticon_list = line[:-1].split(' ')\n",
    "        sentiment = emoticon_list[-1]\n",
    "        emoticon_list = emoticon_list[:-1]\n",
    "        for emoticon in emoticon_list:\n",
    "            emoticons_dict[emoticon] = sentiment\n",
    "populateEmoticonsDict()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "def replace(tweet,words,replacement):\n",
    "    li = []\n",
    "    for word in tweet:\n",
    "        if word in words:\n",
    "            li.append(replacement)\n",
    "        else:\n",
    "            li.append(word)\n",
    "    return li\n",
    "\n",
    "def processTweet(tweet):\n",
    "    emotionFreeTweet = mapEmoticons(tweet)\n",
    "    tagFreeTweet = removeTags(emotionFreeTweet)\n",
    "    lowerCaseTweet = tagFreeTweet.lower()\n",
    "    ptweet = replace(lowerCaseTweet.split(' '),pwords,'positive')\n",
    "    ntweet = replace(ptweet,nwords,'negative')\n",
    "    t = ' '.join(ntweet)\n",
    "    puncFreeTweet = removePunctuations(t)\n",
    "    stopFreeTweet = removeStopWords(puncFreeTweet, stop_words)\n",
    "    stemmedTweet = stemWords(stopFreeTweet)\n",
    "    return stemmedTweet\n",
    "\n",
    "def stemWords(tweet):\n",
    "    return [stemmer.stem(t) for t in tweet]\n",
    "\n",
    "def mapEmoticons(tweet):\n",
    "    list_words = tweet.split(' ')\n",
    "    newtweet = \"\"\n",
    "    for word in list_words:\n",
    "        if word in emoticons_dict:\n",
    "            newtweet = newtweet + ' ' + emoticons_dict.get(word) \n",
    "        else:\n",
    "            newtweet = newtweet + ' ' + word\n",
    "    return newtweet\n",
    "    \n",
    "\n",
    "def removeTags(tweet):\n",
    "    cleanr = re.compile('(</?[a-zA-Z]+>|https?:\\/\\/[^\\s]*|(^|\\s)RT(\\s|$)|@[^\\s]+|\\d+)')\n",
    "    cleantext = re.sub(cleanr, ' weblink ', tweet)\n",
    "    cleantext = re.sub('(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)',' usermention ',cleantext)\n",
    "    cleantext = re.sub('[^\\sa-zA-Z]+','',cleantext)\n",
    "    cleantext = re.sub('\\s+',' ',cleantext)\n",
    "    return cleantext\n",
    "\n",
    "def removePunctuations(tweet):\n",
    "    exclude = set(string.punctuation) \n",
    "    t = ''\n",
    "    for ch in tweet:\n",
    "        if ch not in exclude:\n",
    "            t+=ch\n",
    "        else:\n",
    "            t+=' '\n",
    "    return tweet\n",
    "\n",
    "def removeStopWords(tweet, stop_words):\n",
    "    words_tokenize = word_tokenize(tweet)\n",
    "    filtered_sentence = words_tokenize #[w for w in words_tokenize if w not in stop_words]\n",
    "    return filtered_sentence #' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negat id rather weblink vote weblink for webli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negat gallup show weblink romney weblink webli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negat by recordhigh margin weblink debat webli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weblink romney weblink will make posit weblink...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negat weblink mitt weblink romney weblink migh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet Class\n",
       "0  negat id rather weblink vote weblink for webli...     1\n",
       "1  negat gallup show weblink romney weblink webli...     1\n",
       "2  negat by recordhigh margin weblink debat webli...     1\n",
       "3  weblink romney weblink will make posit weblink...     1\n",
       "4  negat weblink mitt weblink romney weblink migh...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetProcessFrame.rename(columns={'date':'date','time':'time','Anootated tweet' : 'tweet','Class':'Class'},inplace = True)\n",
    "tweetProcessFrame['tweet'] = tweetProcessFrame['tweet'].apply(processTweet)\n",
    "del tweetProcessFrame['date']\n",
    "del tweetProcessFrame['time']\n",
    "\n",
    "def joinList1(tweetList):\n",
    "    return \" \".join(tweetList)\n",
    "\n",
    "tweetProcessFrame['tweet'] = tweetProcessFrame['tweet'].apply(joinList1)\n",
    "tweetProcessFrame1 = tweetProcessFrame\n",
    "print('tweets after preprocessing')\n",
    "tweetProcessFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spliting training and testing for 80-20 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train, test = train_test_split(tweetProcessFrame, test_size = 0.2)\n",
    "def splitTrainingData(df, train_data_prcnt=80):\n",
    "    msk = np.random.rand(len(df)) < train_data_prcnt/100\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    return train, test\n",
    "tweet_random_df = tweetProcessFrame1.copy()\n",
    "for i in range(0, 50):\n",
    "    split1_df, split2_df = splitTrainingData(tweet_random_df)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "train, test = splitTrainingData(tweet_random_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train['tweet']\n",
    "train_label = train['Class']\n",
    "train_label = pd.to_numeric(train_label)\n",
    "\n",
    "test_data = test['tweet']\n",
    "test_class = test['Class']\n",
    "test_class = pd.to_numeric(test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features = 1500)\n",
    "X_train_counts = count_vect.fit_transform(train_data)\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.602201257862\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.80      0.69       594\n",
      "          0       0.48      0.22      0.30       324\n",
      "          1       0.66      0.62      0.64       354\n",
      "\n",
      "avg / total       0.59      0.60      0.58      1272\n",
      "\n",
      "Confusion Matrix:\n",
      "[[475  62  57]\n",
      " [196  71  57]\n",
      " [118  16 220]]\n",
      "Train Accuracy:0.722589167768\n"
     ]
    }
   ],
   "source": [
    "#Multinimoial NB\n",
    "# mnbd = {   \n",
    "#             'alpha':[(float)(el/1000) for el in range(0,100,1)], \n",
    "#             'fit_prior':(True,False)\n",
    "#         }\n",
    "\n",
    "# clf = GridSearchCV(MultinomialNB(),mnbd).fit(X_train_tf, train_label)\n",
    "\n",
    "# {'alpha': 0.014, 'fit_prior': True}\n",
    "clf = MultinomialNB(alpha= 0.014, fit_prior= True).fit(X_train_tf, train_label)\n",
    "\n",
    "X_test_counts = count_vect.transform(test_data)\n",
    "X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "print('Test Accuracy:'+str(np.mean(predicted == test_class)))\n",
    "\n",
    "print(metrics.classification_report(test_class, predicted))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(test_class, predicted)\n",
    "print(nb_confusion_matrix)\n",
    "\n",
    "predicted_train = clf.predict(X_train_tf)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (Linear SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.613993710692\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.77      0.70       594\n",
      "          0       0.50      0.17      0.25       324\n",
      "          1       0.60      0.76      0.67       354\n",
      "\n",
      "avg / total       0.59      0.61      0.58      1272\n",
      "\n",
      "Confusion Matrix:\n",
      "[[459  43  92]\n",
      " [180  54  90]\n",
      " [ 74  12 268]]\n",
      "Train Accuracy:0.728628043027\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# text_clf_svm = Pipeline([('vect', CountVectorizer(max_features=500)),\n",
    "#                     ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', LinearSVC(C = 0.5, dual=False, random_state= 42, max_iter=10000))])\n",
    "# text_clf_svm = text_clf_svm.fit(train_data, train_label)\n",
    "\n",
    "# parameterssvm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#               'vect__max_features': list(range(500,5500,100)),\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "#               'clf__loss' : ['hinge', 'squared_hinge'],\n",
    "#               'clf__penalty' : ['l2'],\n",
    "#               'clf__C' : [i/10 for i in range(5,9)],\n",
    "#               'clf__multi_class' : ['crammer_singer','ovr']\n",
    "#              }\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(max_features = 1500, ngram_range= (1, 2))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf= True)),\n",
    "                    ('clf', LinearSVC(C = 0.5, loss = 'hinge', penalty = 'l2', random_state= 42, max_iter=10000))]).fit(train_data, train_label)\n",
    "# text_clf_svm = text_clf_svm.fit(train_data,train_label)\n",
    "# text_clf_svm = GridSearchCV(text_clf_svm,parameterssvm,n_jobs=-1).fit(train_data, train_label)\n",
    "# text_clf_svm.best_params_\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(test_data)\n",
    "print('Test Accuracy:'+str(np.mean(predicted_svm == test_class)))\n",
    "print(metrics.classification_report(test_class, predicted_svm))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "linearSVM_confusion_matrix = metrics.confusion_matrix(test_class, predicted_svm)\n",
    "print(linearSVM_confusion_matrix)\n",
    "\n",
    "predicted_svm_train = text_clf_svm.predict(train_data)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_svm_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.629716981132\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.85      0.72       594\n",
      "          0       0.51      0.13      0.20       324\n",
      "          1       0.66      0.71      0.69       354\n",
      "\n",
      "avg / total       0.61      0.63      0.58      1272\n",
      "\n",
      "Confusion Matrix:\n",
      "[[507  29  58]\n",
      " [212  41  71]\n",
      " [ 91  10 253]]\n",
      "Train Accuracy:0.742215512361\n"
     ]
    }
   ],
   "source": [
    "clf1 = MultinomialNB(alpha= 0.094, fit_prior= True)\n",
    "clf2 = SGDClassifier(alpha=0.001,learning_rate='optimal',loss= 'epsilon_insensitive', penalty= 'l2',n_iter = 100, random_state=42)\n",
    "clf3 = LinearSVC(C = 0.5, loss = 'hinge', random_state= 42)\n",
    "clf4 = RandomForestClassifier(n_estimators = 22, class_weight = 'balanced_subsample', random_state = 42,criterion=\"gini\")\n",
    "\n",
    "eclf = Pipeline([('vect', CountVectorizer(max_features=1500,ngram_range=(1,2))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf= True)),\n",
    "                    ('clf', VotingClassifier(estimators=[('mnb', clf1), ('sgd', clf2), ('svm', clf3), ('rf',clf4)], voting='hard'))])\n",
    "\n",
    "eclf = eclf.fit(train_data,train_label)\n",
    "\n",
    "p = eclf.predict(test_data)\n",
    "print('Test Accuracy:'+str(np.mean(p==test_class)))\n",
    "print(metrics.classification_report(test_class, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "voting_confusion_matrix = metrics.confusion_matrix(test_class,p)\n",
    "print(voting_confusion_matrix)\n",
    "\n",
    "predicted_eclf_train = eclf.predict(train_data)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_eclf_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combineFrameData = [train_data, test_data]\n",
    "combineFrameLabel = [train_label, test_class]\n",
    "combineTrainDataDF = pd.concat(combineFrameData)\n",
    "combineTrainLabelDF = pd.concat(combineFrameLabel)\n",
    "count_vect_kfold = CountVectorizer(max_features = 1500)\n",
    "X_train_counts_kfold = count_vect.fit_transform(combineTrainDataDF)\n",
    "tf_transformer_kfold = TfidfTransformer(use_idf=True).fit(X_train_counts_kfold)\n",
    "X_train_tf_kfold = tf_transformer_kfold.transform(X_train_counts_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation accuracy Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.62 (+/- 0.02)\n",
      "[ 0.6231003   0.6231003   0.60578387  0.61339422  0.62557078  0.61796043\n",
      "  0.63318113  0.61187215  0.6194825   0.58841463]\n"
     ]
    }
   ],
   "source": [
    "clf_nb_kfold = MultinomialNB(alpha = 0.014, fit_prior = True)\n",
    "scores = cross_val_score(clf_nb_kfold, X_train_tf_kfold, combineTrainLabelDF, cv=10)\n",
    "clf_nb_kfold = clf_nb_kfold.fit(X_train_tf_kfold, combineTrainLabelDF)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cross Validation Accuracy Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63 (+/- 0.04)\n",
      "[ 0.62006079  0.63069909  0.63165906  0.65144597  0.63622527  0.65144597\n",
      "  0.65144597  0.63774734  0.59208524  0.61890244]\n"
     ]
    }
   ],
   "source": [
    "clf_lsvm_kfold = LinearSVC(C = 0.5, loss = 'hinge', penalty='l2', random_state= 42, max_iter=10000)\n",
    "scores_lsvm = cross_val_score(clf_lsvm_kfold, X_train_tf_kfold, combineTrainLabelDF, cv=10)\n",
    "clf_lsvm_kfold = clf_lsvm_kfold.fit(X_train_tf_kfold, combineTrainLabelDF)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_lsvm.mean(), scores_lsvm.std() * 2))\n",
    "print(scores_lsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weblink romney weblink got weblink less minut ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>weblink mitt negat weblink is beat him up nega...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>i actual posit negat weblink romney weblink s ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>just for that weblink immigr statement weblink...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>this man negat weblink romney negat weblink is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet Class\n",
       "1   weblink romney weblink got weblink less minut ...     1\n",
       "18  weblink mitt negat weblink is beat him up nega...     1\n",
       "31  i actual posit negat weblink romney weblink s ...     1\n",
       "32  just for that weblink immigr statement weblink...     1\n",
       "60  this man negat weblink romney negat weblink is...     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_excel('testing-Obama-Romney-tweets.xlsx', sheetname = 'Romney', header=None)\n",
    "df_test.columns = ['tweet','Class']\n",
    "df_test['Class'] = df_test['Class'].astype(str) \n",
    "inputFrame1 = df_test[df_test.Class == '1']\n",
    "inputFrame2 = df_test[df_test.Class == '-1']\n",
    "inputFrame3 = df_test[df_test.Class == '0']\n",
    "df_test = pd.concat([inputFrame1, inputFrame2, inputFrame3])\n",
    "df_test['tweet'] = df_test['tweet'].apply(processTweet)\n",
    "df_test['tweet'] = df_test['tweet'].apply(joinList1)\n",
    "\n",
    "testcounts = count_vect.transform(df_test['tweet'])\n",
    "test_tfidf = tf_transformer_kfold.transform(testcounts)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.575789473684\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.83      0.70       960\n",
      "          0       0.53      0.23      0.32       555\n",
      "          1       0.50      0.43      0.46       385\n",
      "\n",
      "avg / total       0.56      0.58      0.54      1900\n",
      "\n",
      "Confusion Matrix:\n",
      "[[801  79  80]\n",
      " [343 128  84]\n",
      " [187  33 165]]\n"
     ]
    }
   ],
   "source": [
    "p = clf_nb_kfold.predict(test_tfidf)\n",
    "xy = pd.to_numeric(df_test['Class'])\n",
    "print('Test Accuracy:'+str(np.mean(p == xy)))\n",
    "\n",
    "print(metrics.classification_report(xy, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(xy, p)\n",
    "print(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.597894736842\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.83      0.72       960\n",
      "          0       0.64      0.19      0.30       555\n",
      "          1       0.48      0.60      0.54       385\n",
      "\n",
      "avg / total       0.61      0.60      0.56      1900\n",
      "\n",
      "Confusion Matrix:\n",
      "[[798  40 122]\n",
      " [324 107 124]\n",
      " [135  19 231]]\n"
     ]
    }
   ],
   "source": [
    "p = clf_lsvm_kfold.predict(test_tfidf)\n",
    "xy = pd.to_numeric(df_test['Class'])\n",
    "print('Test Accuracy:'+str(np.mean(p == xy)))\n",
    "\n",
    "print(metrics.classification_report(xy, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(xy, p)\n",
    "print(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.609473684211\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.62      0.87      0.73       960\n",
      "          0       0.68      0.20      0.30       555\n",
      "          1       0.54      0.55      0.54       385\n",
      "\n",
      "avg / total       0.62      0.61      0.57      1900\n",
      "\n",
      "Confusion Matrix:\n",
      "[[836  38  86]\n",
      " [348 109  98]\n",
      " [159  13 213]]\n"
     ]
    }
   ],
   "source": [
    "p = eclf.predict(df_test['tweet'])\n",
    "xy = pd.to_numeric(df_test['Class'])\n",
    "print('Test Accuracy:'+str(np.mean(p == xy)))\n",
    "\n",
    "print(metrics.classification_report(xy, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(xy, p)\n",
    "print(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
