{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading original file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tweets:7182\n",
      "top few tweets:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>Anootated tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-12-10 00:00:00</td>\n",
       "      <td>10:09:00-05:00</td>\n",
       "      <td>Question: If &lt;e&gt;Romney&lt;/e&gt; and &lt;e&gt;Obama&lt;/e&gt; ha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>#&lt;e&gt;obama&lt;/e&gt; debates that Cracker Ass Cracker...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:36-05:00</td>\n",
       "      <td>RT @davewiner Slate: Blame &lt;e&gt;Obama&lt;/e&gt; for fo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:50:08-05:00</td>\n",
       "      <td>@Hollivan @hereistheanswer  Youre missing the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date            time  \\\n",
       "0  2012-10-16 00:00:00  10:28:53-05:00   \n",
       "1  2016-12-10 00:00:00  10:09:00-05:00   \n",
       "2  2012-10-16 00:00:00  10:04:30-05:00   \n",
       "3  2012-10-16 00:00:00  10:00:36-05:00   \n",
       "4  2012-10-16 00:00:00  09:50:08-05:00   \n",
       "\n",
       "                                     Anootated tweet Class  \n",
       "0  Kirkpatrick, who wore a baseball cap embroider...     0  \n",
       "1  Question: If <e>Romney</e> and <e>Obama</e> ha...     2  \n",
       "2  #<e>obama</e> debates that Cracker Ass Cracker...     1  \n",
       "3  RT @davewiner Slate: Blame <e>Obama</e> for fo...     2  \n",
       "4  @Hollivan @hereistheanswer  Youre missing the ...     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('training-Obama-Romney-tweets.xlsx', sheetname = 'Obama')\n",
    "inputFrame = df1\n",
    "inputFrame.dropna(inplace = True)\n",
    "print('Total number of tweets:'+str(len(inputFrame)))\n",
    "print('top few tweets:')\n",
    "inputFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing (cleaning the tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputFrame_test = inputFrame.copy()\n",
    "inputFrame_test['Class'] = inputFrame_test['Class'].astype(str) \n",
    "inputFrame1 = inputFrame_test[inputFrame_test.Class == '1']\n",
    "inputFrame2 = inputFrame_test[inputFrame_test.Class == '-1']\n",
    "inputFrame3 = inputFrame_test[inputFrame_test.Class == '0']\n",
    "inputFrame = pd.concat([inputFrame1, inputFrame2, inputFrame3])\n",
    "tweetProcessFrame = inputFrame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cleaning tweets\n",
    "\n",
    "pwords,words=None, None\n",
    "\n",
    "with open(\"positive-words.txt\") as f:\n",
    "    pwords = [el.strip() for el in f.readlines()]\n",
    "with open(\"negative-words.txt\") as f:\n",
    "    nwords = [el.strip() for el in f.readlines()]\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "emoticons_dict = {}\n",
    "def populateEmoticonsDict():\n",
    "    fileHandler = open('EmoticonsWithPolarity.txt', 'r')\n",
    "    for line in fileHandler:\n",
    "        emoticon_list = line[:-1].split(' ')\n",
    "        sentiment = emoticon_list[-1]\n",
    "        emoticon_list = emoticon_list[:-1]\n",
    "        for emoticon in emoticon_list:\n",
    "            emoticons_dict[emoticon] = sentiment\n",
    "populateEmoticonsDict()\n",
    "\n",
    "def replace(tweet,words,replacement):\n",
    "    li = []\n",
    "    for word in tweet:\n",
    "        if word in words:\n",
    "            li.append(replacement)\n",
    "        else:\n",
    "            li.append(word)\n",
    "    return li\n",
    "\n",
    "def processTweet(tweet):\n",
    "    emotionFreeTweet = mapEmoticons(tweet)\n",
    "    tagFreeTweet = removeTags(emotionFreeTweet)\n",
    "    lowerCaseTweet = tagFreeTweet.lower()\n",
    "    ptweet = replace(lowerCaseTweet.split(' '),pwords,'positive')\n",
    "    ntweet = replace(ptweet,nwords,'negative')\n",
    "    t = ' '.join(ntweet)\n",
    "    puncFreeTweet = removePunctuations(t)\n",
    "    stopFreeTweet = removeStopWords(puncFreeTweet, stop_words)\n",
    "    stemmedTweet = stemWords(stopFreeTweet)\n",
    "    return stemmedTweet\n",
    "\n",
    "def stemWords(tweet):\n",
    "    return [stemmer.stem(t) for t in tweet]\n",
    "\n",
    "def mapEmoticons(tweet):\n",
    "    list_words = tweet.split(' ')\n",
    "    newtweet = \"\"\n",
    "    for word in list_words:\n",
    "        if word in emoticons_dict:\n",
    "            newtweet = newtweet + ' ' + emoticons_dict.get(word) \n",
    "        else:\n",
    "            newtweet = newtweet + ' ' + word\n",
    "    return newtweet\n",
    "    \n",
    "\n",
    "def removeTags(tweet):\n",
    "    cleanr = re.compile('(</?[a-zA-Z]+>|https?:\\/\\/[^\\s]*|(^|\\s)RT(\\s|$)|@[^\\s]+|\\d+)')\n",
    "    cleantext = re.sub(cleanr, ' weblink ', tweet)\n",
    "    cleantext = re.sub('(?<=^|(?<=[^a-zA-Z0-9-_\\.]))@([A-Za-z]+[A-Za-z0-9]+)',' usermention ',cleantext)\n",
    "    cleantext = re.sub('[^\\sa-zA-Z]+','',cleantext)\n",
    "    cleantext = re.sub('\\s+',' ',cleantext)\n",
    "    return cleantext\n",
    "\n",
    "def removePunctuations(tweet):\n",
    "    exclude = set(string.punctuation) \n",
    "    t = ''\n",
    "    for ch in tweet:\n",
    "        if ch not in exclude:\n",
    "            t+=ch\n",
    "        else:\n",
    "            t+=' '\n",
    "    return tweet\n",
    "\n",
    "def removeStopWords(tweet, stop_words):\n",
    "    words_tokenize = word_tokenize(tweet)\n",
    "    filtered_sentence = words_tokenize #[w for w in words_tokenize if w not in stop_words]\n",
    "    return filtered_sentence #' '.join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weblink obama weblink debat that cracker ass c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>still my posit mr presid weblink obama weblink</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>weblink you said so much posit thing about web...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weblink im a south african and i say weblink o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>okay weblink obama weblink it is time to put y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet Class\n",
       "2   weblink obama weblink debat that cracker ass c...     1\n",
       "25     still my posit mr presid weblink obama weblink     1\n",
       "29  weblink you said so much posit thing about web...     1\n",
       "32  weblink im a south african and i say weblink o...     1\n",
       "44  okay weblink obama weblink it is time to put y...     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetProcessFrame.rename(columns={'date':'date','time':'time','Anootated tweet' : 'tweet','Class':'Class'},inplace = True)\n",
    "tweetProcessFrame['tweet'] = tweetProcessFrame['tweet'].apply(processTweet)\n",
    "del tweetProcessFrame['time']\n",
    "del tweetProcessFrame['date']\n",
    "def joinList1(tweetList):\n",
    "    return \" \".join(tweetList)\n",
    "\n",
    "tweetProcessFrame['tweet'] = tweetProcessFrame['tweet'].apply(joinList1)\n",
    "tweetProcessFrame1 = pd.DataFrame.drop_duplicates(tweetProcessFrame)\n",
    "print('tweets after preprocessing')\n",
    "tweetProcessFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "spliting training and testing for 80-20 testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train, test = train_test_split(tweetProcessFrame, test_size = 0.2)\n",
    "def splitTrainingData(df, train_data_prcnt=80):\n",
    "    msk = np.random.rand(len(df)) < train_data_prcnt/100\n",
    "    train = df[msk]\n",
    "    test = df[~msk]\n",
    "    return train, test\n",
    "tweet_random_df = tweetProcessFrame1.copy()\n",
    "for i in range(0, 50):\n",
    "    split1_df, split2_df = splitTrainingData(tweet_random_df)\n",
    "    tweet_random_df = pd.concat([split1_df, split2_df])\n",
    "train, test = splitTrainingData(tweet_random_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train['tweet']\n",
    "train_label = train['Class']\n",
    "train_label = pd.to_numeric(train_label)\n",
    "\n",
    "test_data = test['tweet']\n",
    "test_class = test['Class']\n",
    "test_class = pd.to_numeric(test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_features = 4800, ngram_range=(1, 2))\n",
    "X_train_counts = count_vect.fit_transform(train_data)\n",
    "\n",
    "tf_transformer = TfidfTransformer(use_idf=True).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.616246498599\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.70      0.67       402\n",
      "          0       0.58      0.57      0.57       381\n",
      "          1       0.65      0.56      0.60       288\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1071\n",
      "\n",
      "Confusion Matrix:\n",
      "[[282  88  32]\n",
      " [108 217  56]\n",
      " [ 55  72 161]]\n",
      "Train Accuracy:0.762893503014\n"
     ]
    }
   ],
   "source": [
    "# mnbd = {   \n",
    "#             'alpha':[(float)(el/1000) for el in range(0,100,1)], \n",
    "#             'fit_prior':(True,False)\n",
    "#         }\n",
    "\n",
    "clf = MultinomialNB(alpha= 0.99, fit_prior= True).fit(X_train_tf, train_label)\n",
    "#GridSearchCV(MultinomialNB(),mnbd).fit(X_train_tf, train_label)\n",
    "#clf.best_params_\n",
    "# clf = MultinomialNB(alpha= 0.99, fit_prior= True).fit(X_train_tf, train_label)\n",
    "X_test_counts = count_vect.transform(test_data)\n",
    "X_test_tfidf = tf_transformer.transform(X_test_counts)\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "\n",
    "print('Test Accuracy:'+str(np.mean(predicted == test_class)))\n",
    "\n",
    "print(metrics.classification_report(test_class, predicted))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(test_class, predicted)\n",
    "print(nb_confusion_matrix)\n",
    "\n",
    "predicted_train = clf.predict(X_train_tf)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine (Linear SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.629318394024\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.73      0.68       402\n",
      "          0       0.61      0.54      0.58       381\n",
      "          1       0.64      0.60      0.62       288\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1071\n",
      "\n",
      "Confusion Matrix:\n",
      "[[295  74  33]\n",
      " [111 206  64]\n",
      " [ 60  55 173]]\n",
      "Train Accuracy:0.789461933467\n"
     ]
    }
   ],
   "source": [
    "# parameterssvm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#               'vect__max_features': list(range(500,5500,100)),\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "#               'clf__loss' : ['hinge', 'squared_hinge'],\n",
    "#               'clf__penalty' : ['l2'],\n",
    "#               'clf__C' : [i/10 for i in range(5,9)],\n",
    "#               'clf__multi_class' : ['crammer_singer','ovr']\n",
    "#              }\n",
    "\n",
    "# text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "#                     ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', LinearSVC(random_state= 42, max_iter=10000))])\n",
    "# text_clf_svm = text_clf_svm.fit(train_data,train_label)\n",
    "# text_clf_svm = GridSearchCV(text_clf_svm,parameterssvm,n_jobs=-1).fit(train_data, train_label)\n",
    "# text_clf_svm.best_params_\n",
    "\n",
    "# {'clf__C': 0.5,\n",
    "#  'clf__loss': 'hinge',\n",
    "#  'clf__multi_class': 'ovr',\n",
    "#  'clf__penalty': 'l2',\n",
    "#  'tfidf__use_idf': True,\n",
    "#  'vect__max_features': 4800,\n",
    "#  'vect__ngram_range': (1, 2)}\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer(max_features=4800,ngram_range=(1,2))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                    ('clf', LinearSVC(C=0.5,loss='hinge',multi_class='ovr',penalty='l2',random_state= 42, max_iter=10000))]).fit(train_data, train_label)\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(test_data)\n",
    "print('Test Accuracy:'+str(np.mean(predicted_svm == test_class)))\n",
    "print(metrics.classification_report(test_class, predicted_svm))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "linearSVM_confusion_matrix = metrics.confusion_matrix(test_class, predicted_svm)\n",
    "print(linearSVM_confusion_matrix)\n",
    "\n",
    "predicted_svm_train = text_clf_svm.predict(train_data)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_svm_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.621848739496\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.61      0.76      0.68       402\n",
      "          0       0.62      0.52      0.57       381\n",
      "          1       0.64      0.56      0.60       288\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1071\n",
      "\n",
      "Confusion Matrix:\n",
      "[[305  65  32]\n",
      " [124 199  58]\n",
      " [ 69  57 162]]\n",
      "Train Accuracy:0.818932797499\n"
     ]
    }
   ],
   "source": [
    "clf1 = MultinomialNB(alpha= 0.094, fit_prior= True)\n",
    "clf2 = SGDClassifier(alpha=0.001,learning_rate='optimal',loss= 'epsilon_insensitive', penalty= 'l2',n_iter = 100, random_state=42)\n",
    "clf3 = LinearSVC(C = 0.5, loss = 'hinge', random_state= 42)\n",
    "clf4 = RandomForestClassifier(n_estimators = 22, class_weight = 'balanced_subsample', random_state = 42,criterion=\"gini\")\n",
    "\n",
    "eclf = Pipeline([('vect', CountVectorizer(max_features=4800,ngram_range=(1,2))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf= True)),\n",
    "                    ('clf', VotingClassifier(estimators=[('mnb', clf1), ('sgd', clf2), ('svm', clf3), ('rf',clf4)], voting='hard'))])\n",
    "\n",
    "eclf = eclf.fit(train_data,train_label)\n",
    "\n",
    "p = eclf.predict(test_data)\n",
    "print('Test Accuracy:'+str(np.mean(p==test_class)))\n",
    "print(metrics.classification_report(test_class, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "voting_confusion_matrix = metrics.confusion_matrix(test_class,p)\n",
    "print(voting_confusion_matrix)\n",
    "\n",
    "predicted_eclf_train = eclf.predict(train_data)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_eclf_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other approaces tried"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.615312791783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.74      0.66       402\n",
      "          0       0.63      0.50      0.56       381\n",
      "          1       0.62      0.59      0.61       288\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1071\n",
      "\n",
      "Confusion Matrix:\n",
      "[[296  65  41]\n",
      " [126 192  63]\n",
      " [ 69  48 171]]\n",
      "Train Accuracy:0.753962938156\n"
     ]
    }
   ],
   "source": [
    "# parameterssgd = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#               'vect__max_features': list(range(100,5000,500)),\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "#               'clf__loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', \n",
    "#                              'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "#               'clf__penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "#               'clf__learning_rate' : ['optimal','invscaling'],\n",
    "#               'clf__alpha': [i/1000 for i in range(1,10)]\n",
    "#              }\n",
    "# text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "#                     ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', SGDClassifier(n_iter = 100, eta0 = 0.0001, random_state=42))])\n",
    "# text_clf = GridSearchCV(text_clf,parameterssgd,n_jobs=-1).fit(train_data, train_label)\n",
    "# text_clf.best_params_\n",
    "\n",
    "text_clf_sgd = Pipeline([('vect', CountVectorizer(max_features=5000,ngram_range=(1,2))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf= True)),\n",
    "                    ('clf', SGDClassifier(alpha=0.001,learning_rate='optimal',loss= 'epsilon_insensitive'\n",
    "                                          ,penalty= 'l2',n_iter = 100, random_state=42))]).fit(train_data, train_label)\n",
    "\n",
    "predicted_sgd = text_clf_sgd.predict(test_data)\n",
    "print('Test Accuracy:'+str(np.mean(predicted_sgd == test_class)))\n",
    "print(metrics.classification_report(test_class, predicted_sgd))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "linearSGD_confusion_matrix = metrics.confusion_matrix(test_class, predicted_sgd)\n",
    "print(linearSGD_confusion_matrix)\n",
    "\n",
    "predicted_sgd_train = text_clf_sgd.predict(train_data)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_sgd_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.567693744164\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.63      0.60       402\n",
      "          0       0.56      0.56      0.56       381\n",
      "          1       0.57      0.49      0.53       288\n",
      "\n",
      "avg / total       0.57      0.57      0.57      1071\n",
      "\n",
      "Confusion Matrix:\n",
      "[[253  97  52]\n",
      " [113 214  54]\n",
      " [ 77  70 141]]\n",
      "Train Accuracy:0.995088189328\n"
     ]
    }
   ],
   "source": [
    "# parametersrf = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "#               'vect__max_features': list(range(500,5000,100)),\n",
    "#               'tfidf__use_idf': (True, False),\n",
    "#               'clf__criterion' : ['gini','entropy'],\n",
    "#                 'clf__n_estimators' : list(range(2,25,10)),\n",
    "#                 'clf__class_weight' : ['balanced_subsample']\n",
    "#                 }\n",
    "\n",
    "# text_clf_RandomForest = Pipeline([('vect', CountVectorizer()),\n",
    "#                     ('tfidf', TfidfTransformer()),\n",
    "#                     ('clf', RandomForestClassifier(random_state = 42))])\n",
    "# text_clf_RandomForest = GridSearchCV(text_clf_RandomForest,parametersrf,n_jobs=-1).fit(train_data, train_label)\n",
    "# text_clf_RandomForest.best_params_\n",
    "\n",
    "text_clf_RandomForest = Pipeline([('vect', CountVectorizer(max_features = 4700,ngram_range=(1,2))),\n",
    "                    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "                    ('clf', RandomForestClassifier(random_state = 42,criterion=\"gini\",class_weight='balanced_subsample'\n",
    "                                                   ,n_estimators=22))])\n",
    "text_clf_RandomForest = text_clf_RandomForest.fit(train_data, train_label)\n",
    "# {'clf__class_weight': 'balanced_subsample',\n",
    "#  'clf__criterion': 'gini',\n",
    "#  'clf__n_estimators': 22,\n",
    "#  'tfidf__use_idf': True,\n",
    "#  'vect__max_features': 4700,\n",
    "#  'vect__ngram_range': (1, 2)}\n",
    "predicted_rf = text_clf_RandomForest.predict(test_data)\n",
    "print('Test Accuracy:'+str(np.mean(predicted_rf == test_class)))\n",
    "print(metrics.classification_report(test_class, predicted_rf))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "linearRF_confusion_matrix = metrics.confusion_matrix(test_class, predicted_rf)\n",
    "print(linearRF_confusion_matrix)\n",
    "\n",
    "predicted_rf_train = text_clf_RandomForest.predict(train_data)\n",
    "print('Train Accuracy:'+str(np.mean(predicted_rf_train == train_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing Data for Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combineFrameData = [train_data, test_data]\n",
    "combineFrameLabel = [train_label, test_class]\n",
    "combineTrainDataDF = pd.concat(combineFrameData)\n",
    "combineTrainLabelDF = pd.concat(combineFrameLabel)\n",
    "count_vect_kfold = CountVectorizer(max_features = 4800)\n",
    "X_train_counts_kfold = count_vect.fit_transform(combineTrainDataDF)\n",
    "tf_transformer_kfold = TfidfTransformer(use_idf=True).fit(X_train_counts_kfold)\n",
    "X_train_tf_kfold = tf_transformer_kfold.transform(X_train_counts_kfold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation accuracy Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.03)\n",
      "[ 0.58992806  0.5647482   0.58992806  0.59459459  0.5963964   0.58378378\n",
      "  0.56936937  0.55495495  0.59386282  0.59312839]\n"
     ]
    }
   ],
   "source": [
    "clf_nb_kfold = MultinomialNB(alpha = 0.099, fit_prior = True)\n",
    "scores = cross_val_score(clf_nb_kfold, X_train_tf_kfold, combineTrainLabelDF, cv=10)\n",
    "clf_nb_kfold = clf_nb_kfold.fit(X_train_tf_kfold, combineTrainLabelDF)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation Accuracy Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61 (+/- 0.05)\n",
      "[ 0.63489209  0.55215827  0.63669065  0.61441441  0.58018018  0.61621622\n",
      "  0.58558559  0.59099099  0.62274368  0.6238698 ]\n"
     ]
    }
   ],
   "source": [
    "clf_lsvm_kfold = LinearSVC(C = 0.5, loss = 'hinge', penalty='l2', random_state= 42, max_iter=10000)\n",
    "scores_lsvm = cross_val_score(clf_lsvm_kfold, X_train_tf_kfold, combineTrainLabelDF, cv=10)\n",
    "clf_lsvm_kfold = clf_lsvm_kfold.fit(X_train_tf_kfold, combineTrainLabelDF)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_lsvm.mean(), scores_lsvm.std() * 2))\n",
    "print(scores_lsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60 (+/- 0.05)\n",
      "[ 0.63309353  0.55755396  0.64388489  0.60540541  0.58918919  0.61441441\n",
      "  0.6036036   0.56756757  0.61552347  0.60759494]\n"
     ]
    }
   ],
   "source": [
    "clf_sgd_kfold = SGDClassifier(alpha=0.001,learning_rate='optimal',loss= 'epsilon_insensitive', penalty= 'l2',n_iter = 100, random_state=42)\n",
    "scores_sgd = cross_val_score(clf_sgd_kfold, X_train_tf_kfold, combineTrainLabelDF, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_sgd.mean(), scores_sgd.std() * 2))\n",
    "print(scores_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validation accuracy Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.57 (+/- 0.05)\n",
      "[ 0.59352518  0.52877698  0.59532374  0.56756757  0.53333333  0.58378378\n",
      "  0.57837838  0.54234234  0.56498195  0.56238698]\n"
     ]
    }
   ],
   "source": [
    "clf_randomForest_kfold = RandomForestClassifier(n_estimators = 22, class_weight = 'balanced_subsample', random_state = 42, criterion=\"gini\")\n",
    "scores_randomForest = cross_val_score(clf_randomForest_kfold, X_train_tf_kfold, combineTrainLabelDF, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_randomForest.mean(), scores_randomForest.std() * 2))\n",
    "print(scores_randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pickle as pickle\n",
    "# with open('nb_dumped_classifier.pkl', 'wb') as fid:\n",
    "#     pickle.dump(clf, fid)  \n",
    "# with open('svm_dumped_classifier.pkl', 'wb') as fid:\n",
    "#     pickle.dump(text_clf_svm, fid) \n",
    "# with open('voting_dumped_classifier.pkl', 'wb') as fid:\n",
    "#     pickle.dump(eclf, fid) \n",
    "# # load a classifier\n",
    "# with open('svm_dumped_classifier_romney.pkl', 'rb') as fid:\n",
    "#     gnb_loaded = pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weblink obama weblink has to maintain his prof...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>weblink obama weblink went into the debat swin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ditto i start weblink weblink year ago weblink...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>i absolut posit weblink obama weblink s view i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>im agre complet with weblink obama weblink s s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet Class\n",
       "2   weblink obama weblink has to maintain his prof...     1\n",
       "11  weblink obama weblink went into the debat swin...     1\n",
       "21  ditto i start weblink weblink year ago weblink...     1\n",
       "36  i absolut posit weblink obama weblink s view i...     1\n",
       "43  im agre complet with weblink obama weblink s s...     1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_excel('testing-Obama-Romney-tweets.xlsx', sheetname = 'Obama')#, header=None)\n",
    "df_test.columns = ['tweet','Class']\n",
    "df_test['Class'] = df_test['Class'].astype(str) \n",
    "inputFrame1 = df_test[df_test.Class == '1']\n",
    "inputFrame2 = df_test[df_test.Class == '-1']\n",
    "inputFrame3 = df_test[df_test.Class == '0']\n",
    "df_test = pd.concat([inputFrame1, inputFrame2, inputFrame3])\n",
    "df_test['tweet'] = df_test['tweet'].apply(processTweet)\n",
    "df_test['tweet'] = df_test['tweet'].apply(joinList1)\n",
    "\n",
    "testcounts = count_vect.transform(df_test['tweet'])\n",
    "test_tfidf = tf_transformer_kfold.transform(testcounts)\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.556637621732\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.55      0.60      0.58       688\n",
      "          0       0.53      0.54      0.53       681\n",
      "          1       0.60      0.53      0.56       582\n",
      "\n",
      "avg / total       0.56      0.56      0.56      1951\n",
      "\n",
      "Confusion Matrix:\n",
      "[[411 187  90]\n",
      " [199 368 114]\n",
      " [131 144 307]]\n"
     ]
    }
   ],
   "source": [
    "p = clf_nb_kfold.predict(test_tfidf)\n",
    "xy = pd.to_numeric(df_test['Class'])\n",
    "print('Test Accuracy:'+str(np.mean(p == xy)))\n",
    "\n",
    "print(metrics.classification_report(xy, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(xy, p)\n",
    "print(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.59354177345\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.58      0.67      0.62       688\n",
      "          0       0.58      0.56      0.57       681\n",
      "          1       0.62      0.55      0.58       582\n",
      "\n",
      "avg / total       0.59      0.59      0.59      1951\n",
      "\n",
      "Confusion Matrix:\n",
      "[[460 139  89]\n",
      " [196 380 105]\n",
      " [133 131 318]]\n"
     ]
    }
   ],
   "source": [
    "p = clf_lsvm_kfold.predict(test_tfidf)\n",
    "xy = pd.to_numeric(df_test['Class'])\n",
    "print('Test Accuracy:'+str(np.mean(p == xy)))\n",
    "\n",
    "print(metrics.classification_report(xy, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(xy, p)\n",
    "print(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:0.593029215787\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.71      0.63       688\n",
      "          0       0.58      0.53      0.55       681\n",
      "          1       0.64      0.53      0.58       582\n",
      "\n",
      "avg / total       0.60      0.59      0.59      1951\n",
      "\n",
      "Confusion Matrix:\n",
      "[[486 126  76]\n",
      " [224 360  97]\n",
      " [138 133 311]]\n"
     ]
    }
   ],
   "source": [
    "p = eclf.predict(df_test['tweet'])\n",
    "xy = pd.to_numeric(df_test['Class'])\n",
    "print('Test Accuracy:'+str(np.mean(p == xy)))\n",
    "\n",
    "print(metrics.classification_report(xy, p))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "nb_confusion_matrix = metrics.confusion_matrix(xy, p)\n",
    "print(nb_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
